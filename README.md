# Neural_Network_Gradient_Descent
Neural network algorithm with gradient descent is implemented without using a neural network library.

# Goal of the project 

A multi layer neural network is implemented with using back propagation
algorithm, mini-batch gradient descent and momentum. Different hyperparameters
are experimented to find optimal model. 

# One hidden layer neural network equations and neural network architecture
 - One hidden layer neural network architecture :
![image](https://user-images.githubusercontent.com/17252665/90631471-7b666280-e22b-11ea-88c9-1e2a16e47e7d.png)
- Equation derivations for one hidden layer
![image](https://user-images.githubusercontent.com/17252665/90631487-828d7080-e22b-11ea-8ce0-a37940cb091e.png)


# Two hidden layer neural network equations and neural network architecture

- Two hidden layer neural network architecture :
![image](https://user-images.githubusercontent.com/17252665/90631493-85886100-e22b-11ea-8ee1-48c5d9d8bd09.png)
- Equation derivations for two hidden layer
![image](https://user-images.githubusercontent.com/17252665/90631499-88835180-e22b-11ea-8764-e12c1f7f639f.png)
